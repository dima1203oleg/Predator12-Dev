#!/usr/bin/env python3
"""
ü§ñ Advanced AI Chat Bot
–†–æ–∑—à–∏—Ä–µ–Ω–∏–π —á–∞—Ç-–±–æ—Ç –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é —Ä—ñ–∑–Ω–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime
import sys
import argparse

class AIBot:
    def __init__(self, base_url="http://localhost:4000"):
        self.base_url = base_url
        self.session = None
        self.current_model = "gpt-4o-mini"
        self.conversation_history = []
        self.stats = {
            'messages_sent': 0,
            'total_tokens': 0,
            'avg_response_time': 0,
            'errors': 0
        }
        
    async def init_session(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è HTTP —Å–µ—Å—ñ—ó"""
        self.session = aiohttp.ClientSession()
        
    async def close_session(self):
        """–ó–∞–∫—Ä–∏—Ç—Ç—è HTTP —Å–µ—Å—ñ—ó"""
        if self.session:
            await self.session.close()
            
    async def get_models(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å–ø–∏—Å–∫—É –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            async with self.session.get(f"{self.base_url}/v1/models") as response:
                data = await response.json()
                return [model['id'] for model in data['data']]
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π: {e}")
            return []
            
    async def send_message(self, message, model=None, max_tokens=500, stream=False):
        """–í—ñ–¥–ø—Ä–∞–≤–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ AI"""
        if not model:
            model = self.current_model
            
        start_time = time.time()
        
        try:
            payload = {
                'model': model,
                'messages': [{'role': 'user', 'content': message}],
                'max_tokens': max_tokens,
                'stream': stream
            }
            
            # –î–æ–¥–∞–≤–∞–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó —Ä–æ–∑–º–æ–≤–∏ (–æ—Å—Ç–∞–Ω–Ω—ñ 10 –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å)
            if self.conversation_history:
                payload['messages'] = self.conversation_history[-10:] + payload['messages']
            
            async with self.session.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=60)
            ) as response:
                
                if response.status == 200:
                    data = await response.json()
                    end_time = time.time()
                    response_time = end_time - start_time
                    
                    # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                    ai_response = data['choices'][0]['message']['content']
                    tokens_used = data.get('usage', {}).get('total_tokens', 0)
                    
                    # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    self.stats['messages_sent'] += 1
                    self.stats['total_tokens'] += tokens_used
                    current_avg = self.stats['avg_response_time']
                    total_messages = self.stats['messages_sent']
                    self.stats['avg_response_time'] = (
                        (current_avg * (total_messages - 1) + response_time) / total_messages
                    )
                    
                    # –î–æ–¥–∞–≤–∞–Ω–Ω—è –¥–æ —ñ—Å—Ç–æ—Ä—ñ—ó
                    self.conversation_history.extend([
                        {'role': 'user', 'content': message},
                        {'role': 'assistant', 'content': ai_response}
                    ])
                    
                    return {
                        'success': True,
                        'response': ai_response,
                        'tokens_used': tokens_used,
                        'response_time': response_time,
                        'model': model
                    }
                else:
                    error_text = await response.text()
                    self.stats['errors'] += 1
                    return {
                        'success': False,
                        'error': f"HTTP {response.status}: {error_text}",
                        'response_time': time.time() - start_time
                    }
                    
        except Exception as e:
            self.stats['errors'] += 1
            return {
                'success': False,
                'error': str(e),
                'response_time': time.time() - start_time
            }
            
    def print_stats(self):
        """–í–∏–≤–µ–¥–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        print("\n" + "="*50)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–û–ó–ú–û–í–ò")
        print("="*50)
        print(f"üí¨ –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ: {self.stats['messages_sent']}")
        print(f"üî¢ –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤: {self.stats['total_tokens']:,}")
        print(f"‚ö° –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {self.stats['avg_response_time']:.2f}—Å")
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∏: {self.stats['errors']}")
        if self.stats['messages_sent'] > 0:
            print(f"‚úÖ –£—Å–ø—ñ—à–Ω—ñ—Å—Ç—å: {((self.stats['messages_sent'] - self.stats['errors']) / self.stats['messages_sent'] * 100):.1f}%")
        print("="*50)
        
    async def interactive_chat(self):
        """–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —á–∞—Ç"""
        print("ü§ñ AI Bot - –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —á–∞—Ç")
        print("–ö–æ–º–∞–Ω–¥–∏: /models, /switch <model>, /stats, /clear, /help, /quit")
        print("-" * 50)
        
        models = await self.get_models()
        print(f"üìã –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
        print(f"üéØ –ü–æ—Ç–æ—á–Ω–∞ –º–æ–¥–µ–ª—å: {self.current_model}")
        print("-" * 50)
        
        while True:
            try:
                user_input = input("\nüí¨ –í–∏: ").strip()
                
                if not user_input:
                    continue
                    
                # –û–±—Ä–æ–±–∫–∞ –∫–æ–º–∞–Ω–¥
                if user_input.startswith('/'):
                    command_parts = user_input.split()
                    command = command_parts[0].lower()
                    
                    if command == '/quit':
                        print("üëã –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!")
                        break
                    elif command == '/models':
                        print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ñ –º–æ–¥–µ–ª—ñ:")
                        for i, model in enumerate(models, 1):
                            current_marker = " ‚Üê –ø–æ—Ç–æ—á–Ω–∞" if model == self.current_model else ""
                            print(f"  {i}. {model}{current_marker}")
                        continue
                    elif command == '/switch':
                        if len(command_parts) > 1:
                            new_model = ' '.join(command_parts[1:])
                            if new_model in models:
                                self.current_model = new_model
                                print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–º—ñ–Ω–µ–Ω–∞ –Ω–∞: {new_model}")
                            else:
                                print(f"‚ùå –ú–æ–¥–µ–ª—å '{new_model}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")
                        else:
                            print("‚ùå –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è: /switch <–Ω–∞–∑–≤–∞_–º–æ–¥–µ–ª—ñ>")
                        continue
                    elif command == '/stats':
                        self.print_stats()
                        continue
                    elif command == '/clear':
                        self.conversation_history = []
                        print("‚úÖ –Ü—Å—Ç–æ—Ä—ñ—è —Ä–æ–∑–º–æ–≤–∏ –æ—á–∏—â–µ–Ω–∞")
                        continue
                    elif command == '/help':
                        print("\nüÜò –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–º–∞–Ω–¥–∏:")
                        print("  /models - –ø–æ–∫–∞–∑–∞—Ç–∏ –≤—Å—ñ –º–æ–¥–µ–ª—ñ")
                        print("  /switch <model> - –∑–º—ñ–Ω–∏—Ç–∏ –º–æ–¥–µ–ª—å")
                        print("  /stats - –ø–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
                        print("  /clear - –æ—á–∏—Å—Ç–∏—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é")
                        print("  /help - –ø–æ–∫–∞–∑–∞—Ç–∏ –¥–æ–ø–æ–º–æ–≥—É")
                        print("  /quit - –≤–∏–π—Ç–∏")
                        continue
                    else:
                        print("‚ùå –ù–µ–≤—ñ–¥–æ–º–∞ –∫–æ–º–∞–Ω–¥–∞. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ /help –¥–ª—è –¥–æ–ø–æ–º–æ–≥–∏")
                        continue
                
                # –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
                print("ü§î –î—É–º–∞—é...", end="", flush=True)
                result = await self.send_message(user_input)
                print("\r" + " " * 20 + "\r", end="", flush=True)
                
                if result['success']:
                    print(f"ü§ñ AI ({result['model']}): {result['response']}")
                    print(f"üìä {result['tokens_used']} —Ç–æ–∫–µ–Ω—ñ–≤ | {result['response_time']:.2f}—Å")
                else:
                    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {result['error']}")
                    
            except KeyboardInterrupt:
                print("\nüëã –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!")
                break
            except Exception as e:
                print(f"\n‚ùå –ù–µ—Å–ø–æ–¥—ñ–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
                
    async def batch_chat(self, messages, model=None):
        """–ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å"""
        results = []
        
        print(f"üöÄ –û–±—Ä–æ–±–∫–∞ {len(messages)} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å...")
        
        for i, message in enumerate(messages, 1):
            print(f"üìù –û–±—Ä–æ–±–∫–∞ {i}/{len(messages)}: {message[:50]}...")
            
            result = await self.send_message(message, model)
            results.append({
                'message': message,
                'result': result
            })
            
            # –ü–∞—É–∑–∞ –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏
            if i < len(messages):
                await asyncio.sleep(1)
                
        return results
        
    async def benchmark_models(self, test_message="–ü—Ä–∏–≤—ñ—Ç! –†–æ–∑–∫–∞–∂–∏ –ø—Ä–æ —Å–µ–±–µ"):
        """–ë–µ–Ω—á–º–∞—Ä–∫ –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π"""
        models = await self.get_models()
        results = []
        
        print(f"üèÅ –ë–µ–Ω—á–º–∞—Ä–∫ {len(models)} –º–æ–¥–µ–ª–µ–π...")
        print(f"üìù –¢–µ—Å—Ç–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {test_message}")
        print("-" * 50)
        
        for i, model in enumerate(models, 1):
            print(f"üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è {i}/{len(models)}: {model}...")
            
            result = await self.send_message(test_message, model, max_tokens=100)
            results.append({
                'model': model,
                'success': result['success'],
                'response_time': result.get('response_time', 0),
                'tokens': result.get('tokens_used', 0),
                'error': result.get('error', '')
            })
            
            if result['success']:
                print(f"  ‚úÖ {result['response_time']:.2f}—Å | {result.get('tokens_used', 0)} —Ç–æ–∫–µ–Ω—ñ–≤")
            else:
                print(f"  ‚ùå {result.get('error', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}")
                
            # –ü–∞—É–∑–∞ –º—ñ–∂ –º–æ–¥–µ–ª—è–º–∏
            await asyncio.sleep(2)
            
        return results

async def main():
    parser = argparse.ArgumentParser(description='Advanced AI Chat Bot')
    parser.add_argument('--mode', choices=['chat', 'batch', 'benchmark'], 
                       default='chat', help='–†–µ–∂–∏–º —Ä–æ–±–æ—Ç–∏')
    parser.add_argument('--model', help='–ú–æ–¥–µ–ª—å –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è')
    parser.add_argument('--url', default='http://localhost:4000', 
                       help='URL API —Å–µ—Ä–≤–µ—Ä–∞')
    parser.add_argument('--messages', nargs='+', 
                       help='–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏')
    
    args = parser.parse_args()
    
    bot = AIBot(args.url)
    await bot.init_session()
    
    try:
        if args.model:
            models = await bot.get_models()
            if args.model in models:
                bot.current_model = args.model
            else:
                print(f"‚ùå –ú–æ–¥–µ–ª—å '{args.model}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")
                return
        
        if args.mode == 'chat':
            await bot.interactive_chat()
        elif args.mode == 'batch':
            if args.messages:
                results = await bot.batch_chat(args.messages, args.model)
                print("\nüìã –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ü–ê–ö–ï–¢–ù–û–á –û–ë–†–û–ë–ö–ò:")
                for i, result in enumerate(results, 1):
                    print(f"\n{i}. {result['message'][:50]}...")
                    if result['result']['success']:
                        print(f"   ‚úÖ {result['result']['response'][:100]}...")
                    else:
                        print(f"   ‚ùå {result['result']['error']}")
            else:
                print("‚ùå –î–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ —Ä–µ–∂–∏–º—É –ø–æ—Ç—Ä—ñ–±–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (--messages)")
        elif args.mode == 'benchmark':
            results = await bot.benchmark_models()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫—É
            successful = [r for r in results if r['success']]
            failed = [r for r in results if not r['success']]
            
            print(f"\nüèÜ –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ë–ï–ù–ß–ú–ê–†–ö–£:")
            print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ: {len(successful)}")
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∏: {len(failed)}")
            
            if successful:
                avg_time = sum(r['response_time'] for r in successful) / len(successful)
                avg_tokens = sum(r['tokens'] for r in successful) / len(successful)
                print(f"‚ö° –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å: {avg_time:.2f}—Å")
                print(f"üî¢ –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–∫–µ–Ω—ñ–≤: {avg_tokens:.1f}")
                
                # –¢–æ–ø-3 –Ω–∞–π—à–≤–∏–¥—à–∏—Ö
                fastest = sorted(successful, key=lambda x: x['response_time'])[:3]
                print(f"\nüöÄ –ù–∞–π—à–≤–∏–¥—à—ñ –º–æ–¥–µ–ª—ñ:")
                for i, result in enumerate(fastest, 1):
                    print(f"  {i}. {result['model']} - {result['response_time']:.2f}—Å")
        
        bot.print_stats()
        
    finally:
        await bot.close_session()

if __name__ == '__main__':
    print("ü§ñ Advanced AI Chat Bot")
    print("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:")
    print("  python3 advanced_ai_bot.py --mode chat")
    print("  python3 advanced_ai_bot.py --mode benchmark")
    print("  python3 advanced_ai_bot.py --mode batch --messages '–ü—Ä–∏–≤—ñ—Ç' '–Ø–∫ —Å–ø—Ä–∞–≤–∏?'")
    print()
    
    asyncio.run(main())
