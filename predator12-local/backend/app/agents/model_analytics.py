#!/usr/bin/env python3
"""
üìä Model Usage Analytics & Monitoring Dashboard
–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª—ñ–∑—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤—Å—ñ—Ö 58 –º–æ–¥–µ–ª–µ–π –≤ multi-agent —Å–∏—Å—Ç–µ–º—ñ
"""

import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict, Counter
from typing import Any
import matplotlib.pyplot as plt
import pandas as pd

class ModelUsageAnalytics:
    """–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –≤ multi-agent —Å–∏—Å—Ç–µ–º—ñ"""
    
    def __init__(self, log_file: str = "model_usage.log"):
        self.log_file = Path(log_file)
        self.usage_stats = defaultdict(lambda: {
            'total_requests': 0,
            'success_count': 0,
            'error_count': 0,
            'avg_response_time': 0.0,
            'total_response_time': 0.0,
            'agents_using': set(),
            'task_types': Counter(),
            'daily_usage': defaultdict(int),
            'hourly_distribution': defaultdict(int),
            'performance_scores': []
        })
        self.agent_stats = defaultdict(lambda: {
            'models_used': Counter(),
            'total_requests': 0,
            'success_rate': 0.0,
            'favorite_model': '',
            'task_distribution': Counter()
        })
        self.load_existing_data()
    
    def log_model_usage(self, model: str, agent: str, task_type: str, 
                       success: bool, response_time: float, 
                       performance_score: float = 0.0):
        """–õ–æ–≥—É–≤–∞–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ"""
        timestamp = datetime.now()
        
        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª—ñ
        stats = self.usage_stats[model]
        stats['total_requests'] += 1
        stats['agents_using'].add(agent)
        stats['task_types'][task_type] += 1
        
        if success:
            stats['success_count'] += 1
        else:
            stats['error_count'] += 1
        
        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —á–∞—Å—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
        stats['total_response_time'] += response_time
        stats['avg_response_time'] = stats['total_response_time'] / stats['total_requests']
        
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –æ—Ü—ñ–Ω–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        if performance_score > 0:
            stats['performance_scores'].append(performance_score)
        
        # –ß–∞—Å–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        date_key = timestamp.strftime('%Y-%m-%d')
        hour_key = timestamp.hour
        stats['daily_usage'][date_key] += 1
        stats['hourly_distribution'][hour_key] += 1
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≥–µ–Ω—Ç–∞
        agent_stats = self.agent_stats[agent]
        agent_stats['models_used'][model] += 1
        agent_stats['total_requests'] += 1
        agent_stats['task_distribution'][task_type] += 1
        
        # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —É–ª—é–±–ª–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ –∞–≥–µ–Ω—Ç–∞
        agent_stats['favorite_model'] = agent_stats['models_used'].most_common(1)[0][0]
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ success rate –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        total_success = sum(1 for m in agent_stats['models_used'] 
                          if self.usage_stats[m]['success_count'] > 0)
        agent_stats['success_rate'] = total_success / len(agent_stats['models_used']) if agent_stats['models_used'] else 0
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ª–æ–≥
        log_entry = {
            'timestamp': timestamp.isoformat(),
            'model': model,
            'agent': agent,
            'task_type': task_type,
            'success': success,
            'response_time': response_time,
            'performance_score': performance_score
        }
        
        self.save_log_entry(log_entry)
    
    def generate_comprehensive_report(self) -> dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–æ–≥–æ –∑–≤—ñ—Ç—É"""
        
        total_models = len(self.usage_stats)
        total_requests = sum(stats['total_requests'] for stats in self.usage_stats.values())
        
        # –¢–æ–ø-–º–æ–¥–µ–ª—ñ –∑–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º
        top_models = sorted(
            [(model, stats['total_requests']) for model, stats in self.usage_stats.items()],
            key=lambda x: x[1], reverse=True
        )[:10]
        
        # –ù–∞–π–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à—ñ –º–æ–¥–µ–ª—ñ
        efficient_models = []
        for model, stats in self.usage_stats.items():
            if stats['total_requests'] > 5:  # –ú—ñ–Ω—ñ–º—É–º –∑–∞–ø–∏—Ç—ñ–≤ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                efficiency = (stats['success_count'] / stats['total_requests']) * 100
                efficient_models.append((model, efficiency, stats['avg_response_time']))
        
        efficient_models.sort(key=lambda x: x[1], reverse=True)
        
        # –†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏
        provider_stats = defaultdict(lambda: {'models': 0, 'requests': 0})
        for model, stats in self.usage_stats.items():
            provider = model.split('/')[0] if '/' in model else 'unknown'
            provider_stats[provider]['models'] += 1
            provider_stats[provider]['requests'] += stats['total_requests']
        
        # –ê–Ω–∞–ª—ñ–∑ –∞–≥–µ–Ω—Ç—ñ–≤
        agent_analysis = {}
        for agent, stats in self.agent_stats.items():
            agent_analysis[agent] = {
                'total_requests': stats['total_requests'],
                'models_count': len(stats['models_used']),
                'favorite_model': stats['favorite_model'],
                'success_rate': f"{stats['success_rate']:.1%}",
                'top_tasks': dict(stats['task_distribution'].most_common(3))
            }
        
        # –ß–∞—Å–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑
        current_date = datetime.now().strftime('%Y-%m-%d')
        today_usage = sum(stats['daily_usage'].get(current_date, 0) for stats in self.usage_stats.values())
        
        # –ü—ñ–∫–æ–≤—ñ –≥–æ–¥–∏–Ω–∏
        all_hourly = defaultdict(int)
        for stats in self.usage_stats.values():
            for hour, count in stats['hourly_distribution'].items():
                all_hourly[hour] += count
        
        peak_hours = sorted(all_hourly.items(), key=lambda x: x[1], reverse=True)[:3]
        
        return {
            "summary": {
                "total_models_available": 58,
                "models_actively_used": total_models,
                "usage_coverage": f"{(total_models/58)*100:.1f}%",
                "total_requests": total_requests,
                "today_requests": today_usage
            },
            "top_models": top_models[:5],
            "most_efficient": efficient_models[:5],
            "provider_distribution": dict(provider_stats),
            "agent_analysis": agent_analysis,
            "time_analysis": {
                "peak_hours": peak_hours,
                "current_date": current_date
            },
            "recommendations": self._generate_recommendations()
        }
    
    def _generate_recommendations(self) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        recommendations = []
        
        # –ê–Ω–∞–ª—ñ–∑ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
        unused_models = []
        for model_id in self._get_all_available_models():
            if model_id not in self.usage_stats or self.usage_stats[model_id]['total_requests'] == 0:
                unused_models.append(model_id)
        
        if unused_models:
            recommendations.append(
                f"üîç {len(unused_models)} –º–æ–¥–µ–ª–µ–π –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è. "
                f"–†–æ–∑–≥–ª—è–Ω—å—Ç–µ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—é: {', '.join(unused_models[:3])}"
            )
        
        # –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        slow_models = []
        for model, stats in self.usage_stats.items():
            if stats['avg_response_time'] > 5.0 and stats['total_requests'] > 10:
                slow_models.append((model, stats['avg_response_time']))
        
        if slow_models:
            slowest = min(slow_models, key=lambda x: x[1])
            recommendations.append(
                f"‚ö° –ú–æ–¥–µ–ª—å {slowest[0]} –º–∞—î –ø–æ–≤—ñ–ª—å–Ω–∏–π —á–∞—Å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ ({slowest[1]:.1f}s). "
                f"–†–æ–∑–≥–ª—è–Ω—å—Ç–µ fallback –æ–ø—Ü—ñ—ó."
            )
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –ø–æ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—é
        high_usage_models = [model for model, stats in self.usage_stats.items() 
                           if stats['total_requests'] > 100]
        
        if high_usage_models:
            recommendations.append(
                f"üìä –í–∏—Å–æ–∫–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞ –º–æ–¥–µ–ª—ñ: {', '.join(high_usage_models[:2])}. "
                f"–†–æ–∑–ø–æ–¥—ñ–ª—ñ—Ç—å –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏."
            )
        
        return recommendations[:5]  # –¢–æ–ø-5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
    
    def _get_all_available_models(self) -> list[str]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å–ø–∏—Å–∫—É –≤—Å—ñ—Ö 58 –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        return [
            # AI21 Labs
            "ai21-labs/ai21-jamba-1.5-large", "ai21-labs/ai21-jamba-1.5-mini",
            # Cohere
            "cohere/cohere-command-a", "cohere/cohere-command-r-08-2024",
            "cohere/cohere-command-r-plus-08-2024", "cohere/cohere-embed-v3-english",
            "cohere/cohere-embed-v3-multilingual",
            # Core42
            "core42/jais-30b-chat",
            # DeepSeek
            "deepseek/deepseek-r1", "deepseek/deepseek-r1-0528", "deepseek/deepseek-v3-0324",
            # Meta
            "meta/llama-3.2-11b-vision-instruct", "meta/llama-3.2-90b-vision-instruct",
            "meta/llama-3.3-70b-instruct", "meta/llama-4-maverick-17b-128e-instruct-fp8",
            "meta/llama-4-scout-17b-16e-instruct", "meta/meta-llama-3.1-405b-instruct",
            "meta/meta-llama-3.1-8b-instruct",
            # Microsoft
            "microsoft/mai-ds-r1", "microsoft/phi-3-medium-128k-instruct",
            "microsoft/phi-3-medium-4k-instruct", "microsoft/phi-3-mini-128k-instruct",
            "microsoft/phi-3-mini-4k-instruct", "microsoft/phi-3-small-128k-instruct",
            "microsoft/phi-3-small-8k-instruct", "microsoft/phi-3.5-mini-instruct",
            "microsoft/phi-3.5-moe-instruct", "microsoft/phi-3.5-vision-instruct",
            "microsoft/phi-4", "microsoft/phi-4-mini-instruct", 
            "microsoft/phi-4-mini-reasoning", "microsoft/phi-4-multimodal-instruct",
            "microsoft/phi-4-reasoning",
            # Mistral AI
            "mistral-ai/codestral-2501", "mistral-ai/ministral-3b",
            "mistral-ai/mistral-large-2411", "mistral-ai/mistral-medium-2505",
            "mistral-ai/mistral-nemo", "mistral-ai/mistral-small-2503",
            # OpenAI
            "openai/gpt-4.1", "openai/gpt-4.1-mini", "openai/gpt-4.1-nano",
            "openai/gpt-4o", "openai/gpt-4o-mini", "openai/gpt-5",
            "openai/gpt-5-chat", "openai/gpt-5-mini", "openai/gpt-5-nano",
            "openai/o1", "openai/o1-mini", "openai/o1-preview",
            "openai/o3", "openai/o3-mini", "openai/o4-mini",
            "openai/text-embedding-3-large", "openai/text-embedding-3-small",
            # xAI
            "xai/grok-3", "xai/grok-3-mini"
        ]
    
    def save_log_entry(self, entry: dict[str, Any]):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–∞–ø–∏—Å—É –≤ –ª–æ–≥"""
        try:
            with open(self.log_file, 'a') as f:
                f.write(json.dumps(entry) + '\n')
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ª–æ–≥—É: {e}")
    
    def load_existing_data(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å–Ω—É—é—á–∏—Ö –¥–∞–Ω–∏—Ö –∑ –ª–æ–≥—É"""
        if not self.log_file.exists():
            return
        
        try:
            with open(self.log_file) as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        self.log_model_usage(
                            entry['model'], entry['agent'], entry['task_type'],
                            entry['success'], entry['response_time'],
                            entry.get('performance_score', 0.0)
                        )
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å–Ω—É—é—á–∏—Ö –¥–∞–Ω–∏—Ö: {e}")
    
    def generate_visual_report(self, save_path: str = "model_usage_report.png"):
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É"""
        try:
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
            
            # 1. –¢–æ–ø-10 –º–æ–¥–µ–ª–µ–π –∑–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º
            top_models = sorted(
                [(model, stats['total_requests']) for model, stats in self.usage_stats.items()],
                key=lambda x: x[1], reverse=True
            )[:10]
            
            if top_models:
                models, counts = zip(*top_models)
                ax1.barh(range(len(models)), counts)
                ax1.set_yticks(range(len(models)))
                ax1.set_yticklabels([m.split('/')[-1][:20] for m in models])
                ax1.set_title('–¢–æ–ø-10 –º–æ–¥–µ–ª–µ–π –∑–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º')
                ax1.set_xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—ñ–≤')
            
            # 2. –†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏
            provider_counts = defaultdict(int)
            for model in self.usage_stats:
                provider = model.split('/')[0] if '/' in model else 'unknown'
                provider_counts[provider] += self.usage_stats[model]['total_requests']
            
            if provider_counts:
                ax2.pie(provider_counts.values(), labels=provider_counts.keys(), autopct='%1.1f%%')
                ax2.set_title('–†–æ–∑–ø–æ–¥—ñ–ª –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏')
            
            # 3. –ü–æ–≥–æ–¥–∏–Ω–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª
            all_hourly = defaultdict(int)
            for stats in self.usage_stats.values():
                for hour, count in stats['hourly_distribution'].items():
                    all_hourly[hour] += count
            
            if all_hourly:
                hours = sorted(all_hourly.keys())
                counts = [all_hourly[h] for h in hours]
                ax3.plot(hours, counts, marker='o')
                ax3.set_title('–ü–æ–≥–æ–¥–∏–Ω–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è')
                ax3.set_xlabel('–ì–æ–¥–∏–Ω–∞ –¥–æ–±–∏')
                ax3.set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—ñ–≤')
                ax3.grid(True)
            
            # 4. –ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π
            efficient_data = []
            for model, stats in self.usage_stats.items():
                if stats['total_requests'] > 5:
                    success_rate = (stats['success_count'] / stats['total_requests']) * 100
                    efficient_data.append((model.split('/')[-1][:15], success_rate, stats['avg_response_time']))
            
            if efficient_data:
                models, success_rates, response_times = zip(*efficient_data[:10])
                
                ax4_twin = ax4.twinx()
                bars1 = ax4.bar(range(len(models)), success_rates, alpha=0.7, label='Success Rate %')
                bars2 = ax4_twin.plot(range(len(models)), response_times, 'ro-', label='Response Time (s)')
                
                ax4.set_xticks(range(len(models)))
                ax4.set_xticklabels(models, rotation=45, ha='right')
                ax4.set_title('–ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π')
                ax4.set_ylabel('Success Rate (%)', color='blue')
                ax4_twin.set_ylabel('Response Time (s)', color='red')
                
                ax4.legend(loc='upper left')
                ax4_twin.legend(loc='upper right')
            
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üìä –í—ñ–∑—É–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {save_path}")
            
        except ImportError:
            print("‚ùå matplotlib –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –í—ñ–∑—É–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π.")
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É: {e}")

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏ –∞–Ω–∞–ª—ñ–∑—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π"""
    analytics = ModelUsageAnalytics()
    
    print("üìä PREDATOR ANALYTICS - MODEL USAGE ANALYTICS")
    print("=" * 60)
    
    # –°–∏–º—É–ª—è—Ü—ñ—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
    test_scenarios = [
        ("deepseek/deepseek-r1", "AnomalyAgent", "anomaly_detection", True, 2.5, 95.0),
        ("openai/gpt-4o-mini", "DatasetAgent", "data_processing", True, 1.2, 88.0),
        ("microsoft/phi-4-reasoning", "SecurityAgent", "threat_analysis", True, 3.1, 92.0),
        ("mistral-ai/mistral-large-2411", "ForecastAgent", "prediction", True, 4.2, 97.0),
        ("meta/meta-llama-3.1-405b-instruct", "CoreOrchestrator", "coordination", True, 5.8, 98.0),
        ("openai/o1", "ArbiterAgent", "decision_making", True, 3.8, 96.0),
        ("cohere/cohere-command-r-plus-08-2024", "OSINTAgent", "information_gathering", False, 6.2, 75.0),
        ("microsoft/phi-3.5-vision-instruct", "OSINTAgent", "image_analysis", True, 2.8, 91.0),
        ("xai/grok-3", "RedTeamAgent", "penetration_testing", True, 4.5, 89.0),
        ("deepseek/deepseek-v3-0324", "AnomalyAgent", "pattern_analysis", True, 2.1, 93.0),
    ]
    
    print("üîÑ –°–∏–º—É–ª—è—Ü—ñ—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π...")
    for scenario in test_scenarios:
        analytics.log_model_usage(*scenario)
        time.sleep(0.1)  # –°–∏–º—É–ª—è—Ü—ñ—è —á–∞—Å–æ–≤–æ—ó –∑–∞—Ç—Ä–∏–º–∫–∏
    
    # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—É
    report = analytics.generate_comprehensive_report()
    
    print("\nüìã –ê–ù–ê–õ–Ü–¢–ò–ß–ù–ò–ô –ó–í–Ü–¢:")
    print(f"   üìä –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    for key, value in report['summary'].items():
        print(f"      ‚Ä¢ {key}: {value}")
    
    print(f"\nüèÜ –¢–æ–ø-5 –º–æ–¥–µ–ª–µ–π –∑–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º:")
    for i, (model, count) in enumerate(report['top_models'], 1):
        print(f"   {i}. {model}: {count} –∑–∞–ø–∏—Ç—ñ–≤")
    
    print(f"\n‚ö° –ù–∞–π–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à—ñ –º–æ–¥–µ–ª—ñ:")
    for i, (model, efficiency, response_time) in enumerate(report['most_efficient'], 1):
        print(f"   {i}. {model}: {efficiency:.1f}% success, {response_time:.1f}s avg")
    
    print(f"\nü§ñ –ê–Ω–∞–ª—ñ–∑ –∞–≥–µ–Ω—Ç—ñ–≤:")
    for agent, stats in report['agent_analysis'].items():
        print(f"   ‚Ä¢ {agent}: {stats['total_requests']} –∑–∞–ø–∏—Ç—ñ–≤, "
              f"—É–ª—é–±–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {stats['favorite_model'].split('/')[-1]}")
    
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:")
    for i, recommendation in enumerate(report['recommendations'], 1):
        print(f"   {i}. {recommendation}")
    
    # –°–ø—Ä–æ–±–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É
    analytics.generate_visual_report()
    
    print(f"\n‚úÖ –ê–Ω–∞–ª—ñ–∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è 58 –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üìÅ –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {analytics.log_file}")

if __name__ == "__main__":
    main()
