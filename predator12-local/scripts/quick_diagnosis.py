#!/usr/bin/env python3
"""
üîç –®–í–ò–î–ö–ê –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –í–°–Ü–• 58 –ú–û–î–ï–õ–ï–ô
–í–∏–∑–Ω–∞—á–∞—î –ø—Ä–∏—á–∏–Ω–∏ –Ω–µ—Ä–æ–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π
"""

import asyncio
import aiohttp
import json

# –í—Å—ñ 58 –º–æ–¥–µ–ª–µ–π –∑ —Å–µ—Ä–≤–µ—Ä–∞
MODELS = [
    "ai21-labs/ai21-jamba-1.5-large", "ai21-labs/ai21-jamba-1.5-mini",
    "cohere/cohere-command-a", "cohere/cohere-command-r-08-2024",
    "cohere/cohere-command-r-plus-08-2024", "cohere/cohere-embed-v3-english",
    "cohere/cohere-embed-v3-multilingual", "core42/jais-30b-chat",
    "deepseek/deepseek-r1", "deepseek/deepseek-r1-0528", "deepseek/deepseek-v3-0324",
    "meta/llama-3.2-11b-vision-instruct", "meta/llama-3.2-90b-vision-instruct",
    "meta/llama-3.3-70b-instruct", "meta/llama-4-maverick-17b-128e-instruct-fp8",
    "meta/llama-4-scout-17b-16e-instruct", "meta/meta-llama-3.1-405b-instruct",
    "meta/meta-llama-3.1-8b-instruct", "microsoft/mai-ds-r1",
    "microsoft/phi-3-medium-128k-instruct", "microsoft/phi-3-medium-4k-instruct",
    "microsoft/phi-3-mini-128k-instruct", "microsoft/phi-3-mini-4k-instruct",
    "microsoft/phi-3-small-128k-instruct", "microsoft/phi-3-small-8k-instruct",
    "microsoft/phi-3.5-mini-instruct", "microsoft/phi-3.5-moe-instruct",
    "microsoft/phi-3.5-vision-instruct", "microsoft/phi-4",
    "microsoft/phi-4-mini-instruct", "microsoft/phi-4-mini-reasoning",
    "microsoft/phi-4-multimodal-instruct", "microsoft/phi-4-reasoning",
    "mistral-ai/codestral-2501", "mistral-ai/ministral-3b",
    "mistral-ai/mistral-large-2411", "mistral-ai/mistral-medium-2505",
    "mistral-ai/mistral-nemo", "mistral-ai/mistral-small-2503",
    "openai/gpt-4.1", "openai/gpt-4.1-mini", "openai/gpt-4.1-nano",
    "openai/gpt-4o", "openai/gpt-4o-mini", "openai/gpt-5",
    "openai/gpt-5-chat", "openai/gpt-5-mini", "openai/gpt-5-nano",
    "openai/o1", "openai/o1-mini", "openai/o1-preview",
    "openai/o3", "openai/o3-mini", "openai/o4-mini",
    "openai/text-embedding-3-large", "openai/text-embedding-3-small",
    "xai/grok-3", "xai/grok-3-mini"
]

async def quick_test_model(session, model):
    """–®–≤–∏–¥–∫–æ —Ç–µ—Å—Ç—É—î –æ–¥–Ω—É –º–æ–¥–µ–ª—å"""
    try:
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": "OK"}],
            "max_tokens": 2,
            "temperature": 0
        }
        
        async with session.post(
            "http://localhost:3011/v1/chat/completions",
            json=payload,
            timeout=aiohttp.ClientTimeout(total=10)
        ) as response:
            
            if response.status == 200:
                return "‚úÖ –ü–†–ê–¶–Æ–Ñ"
            elif response.status == 403:
                return "üí∞ –õ–Ü–ú–Ü–¢ –ë–Æ–î–ñ–ï–¢–£"
            elif response.status == 404:
                return "‚ùå –ù–ï –ó–ù–ê–ô–î–ï–ù–û"
            elif response.status == 400:
                return "‚ö†Ô∏è –ü–û–ú–ò–õ–ö–ê –ó–ê–ü–ò–¢–£"
            else:
                return f"‚ùì HTTP {response.status}"
                
    except asyncio.TimeoutError:
        return "‚è±Ô∏è –¢–ê–ô–ú–ê–£–¢"
    except Exception as e:
        return f"üí• –ü–û–ú–ò–õ–ö–ê: {str(e)[:20]}"

async def diagnose_all():
    """–î—ñ–∞–≥–Ω–æ—Å—Ç—É—î –≤—Å—ñ –º–æ–¥–µ–ª—ñ"""
    results = {
        "working": [],
        "budget_limit": [],
        "not_found": [],
        "bad_request": [],
        "timeout": [],
        "other_errors": []
    }
    
    print("üîç –®–í–ò–î–ö–ê –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê 58 –ú–û–î–ï–õ–ï–ô...")
    
    async with aiohttp.ClientSession() as session:
        for i, model in enumerate(MODELS, 1):
            status = await quick_test_model(session, model)
            print(f"[{i:2d}/58] {model:<45} {status}")
            
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            if status == "‚úÖ –ü–†–ê–¶–Æ–Ñ":
                results["working"].append(model)
            elif status == "üí∞ –õ–Ü–ú–Ü–¢ –ë–Æ–î–ñ–ï–¢–£":
                results["budget_limit"].append(model)
            elif status == "‚ùå –ù–ï –ó–ù–ê–ô–î–ï–ù–û":
                results["not_found"].append(model)
            elif status == "‚ö†Ô∏è –ü–û–ú–ò–õ–ö–ê –ó–ê–ü–ò–¢–£":
                results["bad_request"].append(model)
            elif status == "‚è±Ô∏è –¢–ê–ô–ú–ê–£–¢":
                results["timeout"].append(model)
            else:
                results["other_errors"].append((model, status))
            
            await asyncio.sleep(0.1)  # –ù–µ–≤–µ–ª–∏–∫–∞ –∑–∞—Ç—Ä–∏–º–∫–∞
    
    print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢–ò –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ò:")
    print(f"‚úÖ –ü—Ä–∞—Ü—é—é—á–∏—Ö –º–æ–¥–µ–ª–µ–π: {len(results['working'])}")
    print(f"üí∞ –ó–∞–±–ª–æ–∫–æ–≤–∞–Ω–æ –ª—ñ–º—ñ—Ç–æ–º –±—é–¥–∂–µ—Ç—É: {len(results['budget_limit'])}")
    print(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {len(results['not_found'])}")
    print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∏ –∑–∞–ø–∏—Ç—É: {len(results['bad_request'])}")
    print(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç–∏: {len(results['timeout'])}")
    print(f"‚ùì –Ü–Ω—à—ñ –ø–æ–º–∏–ª–∫–∏: {len(results['other_errors'])}")
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    with open("/Users/dima/Documents/Predator11/DIAGNOSIS_RESULTS.json", "w") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ –ü–†–ê–¶–Æ–Æ–ß–Ü –ú–û–î–ï–õ–Ü ({len(results['working'])}):")
    for model in results["working"]:
        print(f"   {model}")
    
    if results["budget_limit"]:
        print(f"\nüí∞ –ó–ê–ë–õ–û–ö–û–í–ê–ù–Ü –õ–Ü–ú–Ü–¢–û–ú –ë–Æ–î–ñ–ï–¢–£ ({len(results['budget_limit'])}):")
        for model in results["budget_limit"][:10]:  # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 10
            print(f"   {model}")
        if len(results["budget_limit"]) > 10:
            print(f"   ... —Ç–∞ —â–µ {len(results['budget_limit']) - 10}")
    
    return results

if __name__ == "__main__":
    asyncio.run(diagnose_all())
