#!/usr/bin/env python3
"""
üß† –ü–†–û–î–ê–ö–®–ù –†–û–ó–ü–û–î–Ü–õ 21 –†–ï–ê–õ–¨–ù–û –ü–†–ê–¶–Æ–Æ–ß–û–á –ë–ï–ó–ö–û–®–¢–û–í–ù–û–á AI –ú–û–î–ï–õ–Ü
–°–∫–ª–∞–¥–Ω–∞ –ª–æ–≥—ñ–∫–∞ –∑ –∫–æ–Ω–∫—É—Ä—Å–æ–º, –∞—Ä–±—ñ—Ç—Ä–∞–∂–µ–º, fallback —Ç–∞ –∑–∞—Ö–∏—Å—Ç–æ–º –≤—ñ–¥ –ø–µ—Ä–µ–≥—Ä—ñ–≤—É
"""

import json
import yaml
from typing import Dict, List, Any

# üéØ –¢–Ü–õ–¨–ö–ò 21 –†–ï–ê–õ–¨–ù–û –ü–†–ê–¶–Æ–Æ–ß–ê –ë–ï–ó–ö–û–®–¢–û–í–ù–ê –ú–û–î–ï–õ–¨ (–ü–†–û–î–ê–ö–®–ù)
ALL_MODELS = [
    # TIER 1: –ù–ê–ô–ü–û–¢–£–ñ–ù–Ü–®–Ü –ë–ï–ó–ö–û–®–¢–û–í–ù–Ü (5 –º–æ–¥–µ–ª–µ–π)
    "ai21-labs/ai21-jamba-1.5-large",         # –ù–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à–∞ reasoning –º–æ–¥–µ–ª—å
    "mistralai/mixtral-8x7b-instruct-v0.1",   # –ù–∞–π–∫—Ä–∞—â–∞ Mixtral
    "meta-llama/meta-llama-3-70b-instruct",   # –ü–æ—Ç—É–∂–Ω–∞ Llama
    "mistralai/mistral-7b-instruct-v0.3",     # –°—Ç–∞–±—ñ–ª—å–Ω–∞ Mistral
    "microsoft/phi-3-mini-4k-instruct",       # –®–≤–∏–¥–∫–∞ Phi
    
    # TIER 2: –í–ò–°–û–ö–û–ü–†–û–î–£–ö–¢–ò–í–ù–Ü (6 –º–æ–¥–µ–ª–µ–π) 
    "meta-llama/meta-llama-3-8b-instruct",    # –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∞ Llama
    "microsoft/phi-3-mini-128k-instruct",     # –î–æ–≤–≥–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç Phi
    "microsoft/phi-3-small-8k-instruct",      # –ú–∞–ª–∞ Phi
    "microsoft/phi-3-small-128k-instruct",    # –ú–∞–ª–∞ Phi –∑ –¥–æ–≤–≥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    "qwen/qwen2.5-7b-instruct",               # Qwen —Å–µ—Ä–µ–¥–Ω—è
    "qwen/qwen2.5-32b-instruct",              # Qwen –≤–µ–ª–∏–∫–∞
    
    # TIER 3: –°–ü–ï–¶–Ü–ê–õ–Ü–ó–û–í–ê–ù–Ü (5 –º–æ–¥–µ–ª–µ–π)
    "cohere/command-r-plus-08-2024",          # –ù–∞–π–∫—Ä–∞—â–∞ Command
    "cohere/command-r-08-2024",               # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ Command
    "mistralai/codestral-latest",             # –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –¥–ª—è –∫–æ–¥—É
    "google/gemma-2-27b-it",                  # Google Gemma
    "meta-llama/llama-3.2-3b-instruct",      # –ú–∞–ª–∞ Llama
    
    # TIER 4: –®–í–ò–î–ö–Ü/–õ–ï–ì–ö–Ü (5 –º–æ–¥–µ–ª–µ–π)
    "meta-llama/llama-3.2-1b-instruct",      # –ù–∞–π—à–≤–∏–¥—à–∞ Llama
    "qwen/qwen2.5-3b-instruct",               # –®–≤–∏–¥–∫–∞ Qwen
    "qwen/qwen2.5-1.5b-instruct",            # –£–ª—å—Ç—Ä–∞—à–≤–∏–¥–∫–∞ Qwen
    "qwen/qwen2.5-0.5b-instruct",            # –ù–∞–π–º–µ–Ω—à–∞ Qwen
    "microsoft/phi-3-medium-4k-instruct"      # –°–µ—Ä–µ–¥–Ω—è Phi
]

# ü§ñ 26 –ê–ì–ï–ù–¢–Ü–í –ó –ü–†–û–î–ê–ö–®–ù –õ–û–ì–Ü–ö–û–Æ: –ö–û–ù–ö–£–†–° + –ê–†–ë–Ü–¢–†–ê–ñ + FALLBACK + –ê–ù–¢–ò–ü–ï–†–ï–ì–†–Ü–í
AGENT_SPECIFICATIONS = {
    # üéØ –ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–õ–ò–í–Ü –ê–ì–ï–ù–¢–ò (–ù–ê–ô–ö–†–ê–©–Ü –ú–û–î–ï–õ–Ü + –ö–û–ù–ö–£–†–°)
    "ChiefOrchestrator": {
        "category": "critical_orchestration",
        "specialization": "–ö–µ—Ä—É–≤–∞–Ω–Ω—è –≤—Å—ñ–º–∞ –∞–≥–µ–Ω—Ç–∞–º–∏ —Ç–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª –∑–∞–≤–¥–∞–Ω—å",
        "competition_models": [
            "ai21-labs/ai21-jamba-1.5-large",     # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç 1 - –Ω–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à–∞
            "mistralai/mixtral-8x7b-instruct-v0.1", # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç 2 - –Ω–∞–π–∫—Ä–∞—â–∞ Mixtral
            "meta-llama/meta-llama-3-70b-instruct"  # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç 3 - –ø–æ—Ç—É–∂–Ω–∞ Llama
        ],
        "arbiter_model": "cohere/command-r-plus-08-2024", # –ê—Ä–±—ñ—Ç—Ä –¥–ª—è –≤–∏–±–æ—Ä—É
        "fallback_chain": [
            "mistralai/mistral-7b-instruct-v0.3",
            "microsoft/phi-3-mini-4k-instruct", 
            "meta-llama/meta-llama-3-8b-instruct"
        ],
        "emergency_pool": ["microsoft/phi-3-mini-128k-instruct", "qwen/qwen2.5-7b-instruct"],
        "max_concurrent": 5,
        "thermal_protection": {"enabled": True, "threshold": 0.85, "cooldown": 45},
        "load_balancing": "competition_winner"
    },
    
    "ModelRouter": {
        "category": "critical_routing",
        "specialization": "–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—è –∑–∞–ø–∏—Ç—ñ–≤ –º—ñ–∂ –º–æ–¥–µ–ª—è–º–∏ —Ç–∞ –∞–≥–µ–Ω—Ç–∞–º–∏",
        "competition_models": [
            "meta-llama/meta-llama-3-70b-instruct",   # –®–≤–∏–¥–∫—ñ—Å—Ç—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—ó
            "microsoft/phi-3-small-128k-instruct",    # –î–æ–≤–≥–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            "cohere/command-r-plus-08-2024"           # –Ø–∫—ñ—Å—Ç—å —Ä—ñ—à–µ–Ω—å
        ],
        "arbiter_model": "mistralai/mistral-7b-instruct-v0.3",
        "fallback_chain": [
            "microsoft/phi-3-mini-4k-instruct",
            "qwen/qwen2.5-7b-instruct",
            "meta-llama/meta-llama-3-8b-instruct"
        ],
        "emergency_pool": ["qwen/qwen2.5-32b-instruct", "google/gemma-2-27b-it"],
        "max_concurrent": 4,
        "thermal_protection": {"enabled": True, "threshold": 0.80, "cooldown": 30},
        "load_balancing": "fastest_accurate"
    },
    
    "QueryPlanner": {
        "category": "critical_planning",
        "specialization": "–ü–ª–∞–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–ø–∏—Ç—ñ–≤",
        "competition_models": [
            "ai21-labs/ai21-jamba-1.5-large",      # –°–∫–ª–∞–¥–Ω–µ –ø–ª–∞–Ω—É–≤–∞–Ω–Ω—è
            "cohere/command-r-plus-08-2024",       # –°—Ç—Ä—É–∫—Ç—É—Ä—É–≤–∞–Ω–Ω—è
            "mistralai/mixtral-8x7b-instruct-v0.1" # –õ–æ–≥—ñ–∫–∞
        ],
        "arbiter_model": "meta-llama/meta-llama-3-70b-instruct",
        "fallback_chain": [
            "microsoft/phi-3-small-8k-instruct",
            "qwen/qwen2.5-32b-instruct",
            "cohere/command-r-08-2024"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "microsoft/phi-3-mini-128k-instruct"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 60},
        "load_balancing": "consensus_vote"
    },
    
    # üî• –í–ò–°–û–ö–û–ù–ê–í–ê–ù–¢–ê–ñ–ï–ù–Ü –ê–ì–ï–ù–¢–ò (–®–í–ò–î–ö–Ü–°–¢–¨ + –ù–ê–î–Ü–ô–ù–Ü–°–¢–¨)
    "DataQuality": {
        "category": "high_load_analysis",
        "specialization": "–ê–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö —Ç–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π",
        "competition_models": [
            "meta-llama/meta-llama-3-8b-instruct",   # –®–≤–∏–¥–∫–∏–π –∞–Ω–∞–ª—ñ–∑
            "microsoft/phi-3-mini-128k-instruct",    # –î–æ–≤–≥—ñ –¥–∞–Ω—ñ
            "qwen/qwen2.5-7b-instruct"               # –¢–æ—á–Ω—ñ—Å—Ç—å
        ],
        "arbiter_model": "cohere/command-r-08-2024",
        "fallback_chain": [
            "microsoft/phi-3-small-8k-instruct",
            "qwen/qwen2.5-3b-instruct",
            "meta-llama/llama-3.2-3b-instruct"
        ],
        "emergency_pool": ["microsoft/phi-3-mini-4k-instruct", "qwen/qwen2.5-1.5b-instruct"],
        "max_concurrent": 8,
        "thermal_protection": {"enabled": True, "threshold": 0.70, "cooldown": 20},
        "load_balancing": "round_robin_fast"
    },
    
    "Anomaly": {
        "category": "real_time_detection",
        "specialization": "–í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ",
        "competition_models": [
            "microsoft/phi-3-small-8k-instruct",     # –®–≤–∏–¥–∫–∞ –¥–µ—Ç–µ–∫—Ü—ñ—è
            "qwen/qwen2.5-7b-instruct",              # –¢–æ—á–Ω—ñ—Å—Ç—å –≤–∏—è–≤–ª–µ–Ω–Ω—è
            "meta-llama/llama-3.2-3b-instruct"      # –ù–∏–∑—å–∫–∞ –ª–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å
        ],
        "arbiter_model": "cohere/command-r-08-2024",
        "fallback_chain": [
            "microsoft/phi-3-mini-4k-instruct",
            "qwen/qwen2.5-3b-instruct", 
            "meta-llama/llama-3.2-1b-instruct"
        ],
        "emergency_pool": ["qwen/qwen2.5-1.5b-instruct", "qwen/qwen2.5-0.5b-instruct"],
        "max_concurrent": 10,
        "thermal_protection": {"enabled": True, "threshold": 0.65, "cooldown": 15},
        "load_balancing": "ultra_fast"
    },
    
    "Forecast": {
        "category": "predictive_analytics", 
        "specialization": "–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ç–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è —Ç—Ä–µ–Ω–¥—ñ–≤",
        "competition_models": [
            "mistralai/mixtral-8x7b-instruct-v0.1",  # –°–∫–ª–∞–¥–Ω—ñ –ø—Ä–æ–≥–Ω–æ–∑–∏
            "ai21-labs/ai21-jamba-1.5-large",        # –î–æ–≤–≥–æ—Å—Ç—Ä–æ–∫–æ–≤—ñ —Ç—Ä–µ–Ω–¥–∏
            "qwen/qwen2.5-32b-instruct"               # –ß–∏—Å–ª–æ–≤—ñ –¥–∞–Ω—ñ
        ],
        "arbiter_model": "meta-llama/meta-llama-3-70b-instruct",
        "fallback_chain": [
            "cohere/command-r-plus-08-2024",
            "microsoft/phi-3-small-128k-instruct",
            "qwen/qwen2.5-7b-instruct"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "meta-llama/meta-llama-3-8b-instruct"],
        "max_concurrent": 5,
        "thermal_protection": {"enabled": True, "threshold": 0.80, "cooldown": 40},
        "load_balancing": "accuracy_weighted"
    },
    
    # üõ†Ô∏è –°–ü–ï–¶–Ü–ê–õ–Ü–ó–û–í–ê–ù–Ü –ê–ì–ï–ù–¢–ò (–ï–ö–°–ü–ï–†–¢–ù–Ü –ú–û–î–ï–õ–Ü)
    "AutoHeal": {
        "category": "code_generation_healing",
        "specialization": "–ê–≤—Ç–æ–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –∫–æ–¥—É —Ç–∞ —Å–∏—Å—Ç–µ–º–∏",
        "competition_models": [
            "mistralai/codestral-latest",             # –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ –∫–æ–¥—É
            "ai21-labs/ai21-jamba-1.5-large",        # –°–∫–ª–∞–¥–Ω–∞ –ª–æ–≥—ñ–∫–∞
            "microsoft/phi-3-small-128k-instruct"    # –î–æ–≤–≥–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥—É
        ],
        "arbiter_model": "cohere/command-r-plus-08-2024",
        "fallback_chain": [
            "meta-llama/meta-llama-3-8b-instruct",
            "qwen/qwen2.5-7b-instruct",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["microsoft/phi-3-mini-128k-instruct", "google/gemma-2-27b-it"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 30},
        "load_balancing": "code_quality_score"
    },
    
    "SelfDiagnosis": {
        "category": "system_diagnostics",
        "specialization": "–°–∞–º–æ–¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º–∏ —Ç–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º", 
        "competition_models": [
            "meta-llama/meta-llama-3-70b-instruct",  # –ì–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑
            "microsoft/phi-3-small-128k-instruct",   # –°–∏—Å—Ç–µ–º–Ω—ñ –ª–æ–≥–∏
            "cohere/command-r-08-2024"               # –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –∑–≤—ñ—Ç
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "qwen/qwen2.5-32b-instruct",
            "google/gemma-2-27b-it",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["microsoft/phi-3-mini-4k-instruct", "meta-llama/meta-llama-3-8b-instruct"],
        "max_concurrent": 4,
        "thermal_protection": {"enabled": True, "threshold": 0.70, "cooldown": 35},
        "load_balancing": "diagnostic_depth"
    },
    
    # üöÄ –®–í–ò–î–ö–Ü –ê–ì–ï–ù–¢–ò (–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê –ü–†–û–ü–£–°–ö–ù–ê –ó–î–ê–¢–ù–Ü–°–¢–¨)
    "DatasetIngest": {
        "category": "fast_processing",
        "specialization": "–®–≤–∏–¥–∫–µ –ø–æ–≥–ª–∏–Ω–∞–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö",
        "competition_models": [
            "meta-llama/llama-3.2-1b-instruct",      # –ù–∞–π—à–≤–∏–¥—à–∞
            "qwen/qwen2.5-3b-instruct",              # –®–≤–∏–¥–∫–∞ + —è–∫—ñ—Å–Ω–∞
            "microsoft/phi-3-mini-4k-instruct"       # –°—Ç–∞–±—ñ–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å
        ],
        "arbiter_model": "microsoft/phi-3-small-8k-instruct",
        "fallback_chain": [
            "qwen/qwen2.5-1.5b-instruct",
            "qwen/qwen2.5-0.5b-instruct",
            "microsoft/phi-3-medium-4k-instruct"
        ],
        "emergency_pool": ["meta-llama/llama-3.2-3b-instruct", "cohere/command-r-08-2024"],
        "max_concurrent": 15,
        "thermal_protection": {"enabled": True, "threshold": 0.60, "cooldown": 10},
        "load_balancing": "maximum_throughput"
    },
    
    "ETLOrchestrator": {
        "category": "data_transformation", 
        "specialization": "–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—è ETL –ø—Ä–æ—Ü–µ—Å—ñ–≤",
        "competition_models": [
            "microsoft/phi-3-small-128k-instruct",   # –î–æ–≤–≥—ñ –ø–∞–π–ø–ª–∞–π–Ω–∏
            "qwen/qwen2.5-7b-instruct",              # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö
            "meta-llama/meta-llama-3-8b-instruct"   # –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü—ñ—è
        ],
        "arbiter_model": "cohere/command-r-plus-08-2024",
        "fallback_chain": [
            "google/gemma-2-27b-it",
            "mistralai/mistral-7b-instruct-v0.3",
            "microsoft/phi-3-mini-128k-instruct"
        ],
        "emergency_pool": ["qwen/qwen2.5-32b-instruct", "meta-llama/llama-3.2-3b-instruct"],
        "max_concurrent": 8,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 25},
        "load_balancing": "pipeline_efficiency"
    },
    
    # üîç –Ü–ù–î–ï–ö–°–ê–¶–Ü–Ø –¢–ê –ü–û–®–£–ö
    "Indexer": {
        "category": "indexing_search",
        "specialization": "–Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö —Ç–∞ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫",
        "competition_models": [
            "cohere/command-r-08-2024",              # –°–µ–º–∞–Ω—Ç–∏–∫–∞
            "qwen/qwen2.5-7b-instruct",              # –Ü–Ω–¥–µ–∫—Å–∞—Ü—ñ—è
            "microsoft/phi-3-mini-128k-instruct"    # –î–æ–≤–≥–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        ],
        "arbiter_model": "meta-llama/meta-llama-3-8b-instruct",
        "fallback_chain": [
            "google/gemma-2-27b-it",
            "qwen/qwen2.5-3b-instruct",
            "microsoft/phi-3-small-8k-instruct"
        ],
        "emergency_pool": ["meta-llama/llama-3.2-3b-instruct", "qwen/qwen2.5-1.5b-instruct"],
        "max_concurrent": 6,
        "thermal_protection": {"enabled": True, "threshold": 0.70, "cooldown": 20},
        "load_balancing": "search_relevance"
    },
    
    "Embedding": {
        "category": "embeddings_vectors", 
        "specialization": "–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—å",
        "competition_models": [
            "cohere/command-r-plus-08-2024",         # –ù–∞–π–∫—Ä–∞—â—ñ embeddings
            "qwen/qwen2.5-32b-instruct",             # –í–µ–ª–∏–∫—ñ –≤–µ–∫—Ç–æ—Ä–∏
            "microsoft/phi-3-small-128k-instruct"   # –î–æ–≤–≥–∏–π —Ç–µ–∫—Å—Ç
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "meta-llama/meta-llama-3-8b-instruct",
            "google/gemma-2-27b-it", 
            "cohere/command-r-08-2024"
        ],
        "emergency_pool": ["qwen/qwen2.5-7b-instruct", "mistralai/mistral-7b-instruct-v0.3"],
        "max_concurrent": 12,
        "thermal_protection": {"enabled": True, "threshold": 0.65, "cooldown": 15},
        "load_balancing": "vector_quality"
    },
    
    # üåê –í–ï–ë –¢–ê OSINT –ê–ì–ï–ù–¢–ò
    "OSINTCrawler": {
        "category": "web_intelligence",
        "specialization": "–ó–±—ñ—Ä —Ä–æ–∑–≤—ñ–¥—É–≤–∞–ª—å–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑ –≤—ñ–¥–∫—Ä–∏—Ç–∏—Ö –¥–∂–µ—Ä–µ–ª",
        "competition_models": [
            "meta-llama/llama-3.2-3b-instruct",      # –®–≤–∏–¥–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥
            "qwen/qwen2.5-3b-instruct",              # –ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç–µ–Ω—Ç—É  
            "microsoft/phi-3-mini-4k-instruct"       # –°—Ç—Ä—É–∫—Ç—É—Ä—É–≤–∞–Ω–Ω—è
        ],
        "arbiter_model": "cohere/command-r-08-2024",
        "fallback_chain": [
            "qwen/qwen2.5-1.5b-instruct",
            "meta-llama/llama-3.2-1b-instruct",
            "microsoft/phi-3-medium-4k-instruct"
        ],
        "emergency_pool": ["qwen/qwen2.5-0.5b-instruct", "google/gemma-2-27b-it"],
        "max_concurrent": 10,
        "thermal_protection": {"enabled": True, "threshold": 0.60, "cooldown": 12},
        "load_balancing": "crawl_speed"
    },
    
    "GraphBuilder": {
        "category": "graph_analysis",
        "specialization": "–ü–æ–±—É–¥–æ–≤–∞ —Ç–∞ –∞–Ω–∞–ª—ñ–∑ –≥—Ä–∞—Ñ—ñ–≤ –∑–≤'—è–∑–∫—ñ–≤",
        "competition_models": [
            "ai21-labs/ai21-jamba-1.5-large",        # –°–∫–ª–∞–¥–Ω—ñ –∑–≤'—è–∑–∫–∏
            "microsoft/phi-3-small-128k-instruct",   # –í–µ–ª–∏–∫—ñ –≥—Ä–∞—Ñ–∏
            "qwen/qwen2.5-32b-instruct"              # –ê–Ω–∞–ª—ñ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä
        ],
        "arbiter_model": "meta-llama/meta-llama-3-70b-instruct",
        "fallback_chain": [
            "cohere/command-r-plus-08-2024",
            "google/gemma-2-27b-it",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["meta-llama/meta-llama-3-8b-instruct", "qwen/qwen2.5-7b-instruct"],
        "max_concurrent": 4,
        "thermal_protection": {"enabled": True, "threshold": 0.80, "cooldown": 35},
        "load_balancing": "graph_complexity"
    },
    
    # üé≤ –°–ò–ú–£–õ–Ø–¶–Ü–Ø –¢–ê –î–ê–ù–Ü
    "Simulator": {
        "category": "simulation_modeling",
        "specialization": "–ú–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è —Ç–∞ —Å–∏–º—É–ª—è—Ü—ñ—è —Å—Ü–µ–Ω–∞—Ä—ñ—ó–≤",
        "competition_models": [
            "mistralai/mixtral-8x7b-instruct-v0.1",  # –°–∫–ª–∞–¥–Ω—ñ –º–æ–¥–µ–ª—ñ
            "qwen/qwen2.5-32b-instruct",              # –ß–∏—Å–ª–æ–≤—ñ —Å–∏–º—É–ª—è—Ü—ñ—ó
            "microsoft/phi-3-small-128k-instruct"    # –î–æ–≤–≥—ñ —Å—Ü–µ–Ω–∞—Ä—ñ—ó
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "cohere/command-r-plus-08-2024",
            "meta-llama/meta-llama-3-8b-instruct", 
            "google/gemma-2-27b-it"
        ],
        "emergency_pool": ["qwen/qwen2.5-7b-instruct", "mistralai/mistral-7b-instruct-v0.3"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.85, "cooldown": 50},
        "load_balancing": "simulation_accuracy"
    },
    
    "SyntheticData": {
        "category": "data_generation",
        "specialization": "–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö",
        "competition_models": [
            "cohere/command-r-plus-08-2024",         # –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ –¥–∞–Ω—ñ
            "microsoft/phi-3-small-128k-instruct",  # –î–æ–≤–≥—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏
            "qwen/qwen2.5-7b-instruct"               # –†—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å
        ],
        "arbiter_model": "meta-llama/meta-llama-3-70b-instruct",
        "fallback_chain": [
            "ai21-labs/ai21-jamba-1.5-large",
            "google/gemma-2-27b-it",
            "meta-llama/meta-llama-3-8b-instruct"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "qwen/qwen2.5-32b-instruct"],
        "max_concurrent": 5,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 30},
        "load_balancing": "data_diversity"
    },
    
    # üìä –ó–í–Ü–¢–ù–Ü–°–¢–¨ –¢–ê –î–û–ö–£–ú–ï–ù–¢–ò  
    "ReportExport": {
        "category": "document_generation",
        "specialization": "–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–≤—ñ—Ç—ñ–≤ —Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—ó",
        "competition_models": [
            "cohere/command-r-plus-08-2024",         # –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –∑–≤—ñ—Ç–∏
            "microsoft/phi-3-small-128k-instruct",  # –î–æ–≤–≥—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏
            "meta-llama/meta-llama-3-8b-instruct"   # –Ø–∫—ñ—Å–Ω–∏–π —Ç–µ–∫—Å—Ç
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "qwen/qwen2.5-32b-instruct",
            "google/gemma-2-27b-it",
            "cohere/command-r-08-2024"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "qwen/qwen2.5-7b-instruct"],
        "max_concurrent": 4,
        "thermal_protection": {"enabled": True, "threshold": 0.70, "cooldown": 25},
        "load_balancing": "document_quality"
    },
    
    # üí∞ –§–Ü–ù–ê–ù–°–ò –¢–ê –ë–Ü–õ–õ–Ü–ù–ì
    "BillingGate": {
        "category": "financial_analysis",
        "specialization": "–ê–Ω–∞–ª—ñ–∑ —Ñ—ñ–Ω–∞–Ω—Å—ñ–≤ —Ç–∞ –±—ñ–ª–ª—ñ–Ω–≥—É",
        "competition_models": [
            "qwen/qwen2.5-32b-instruct",             # –ß–∏—Å–ª–æ–≤—ñ –¥–∞–Ω—ñ
            "microsoft/phi-3-small-8k-instruct",    # –§—ñ–Ω–∞–Ω—Å–æ–≤–∞ –ª–æ–≥—ñ–∫–∞
            "cohere/command-r-08-2024"               # –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "meta-llama/meta-llama-3-8b-instruct",
            "google/gemma-2-27b-it",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["qwen/qwen2.5-7b-instruct", "microsoft/phi-3-mini-128k-instruct"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.80, "cooldown": 40},
        "load_balancing": "financial_accuracy"
    },
    
    # üõ°Ô∏è –ë–ï–ó–ü–ï–ö–ê –¢–ê –ó–ê–•–ò–°–¢
    "PIIGuardian": {
        "category": "privacy_protection", 
        "specialization": "–ó–∞—Ö–∏—Å—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö —Ç–∞ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—ñ",
        "competition_models": [
            "microsoft/phi-3-small-128k-instruct",   # –í–∏—è–≤–ª–µ–Ω–Ω—è PII
            "cohere/command-r-plus-08-2024",         # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
            "qwen/qwen2.5-7b-instruct"               # –ê–Ω–∞–ª—ñ–∑ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—ñ
        ],
        "arbiter_model": "meta-llama/meta-llama-3-70b-instruct",
        "fallback_chain": [
            "ai21-labs/ai21-jamba-1.5-large",
            "google/gemma-2-27b-it",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["meta-llama/meta-llama-3-8b-instruct", "cohere/command-r-08-2024"],
        "max_concurrent": 6,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 30},
        "load_balancing": "privacy_score"
    },
    
    "RedTeam": {
        "category": "security_testing",
        "specialization": "–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –±–µ–∑–ø–µ–∫–∏ —Ç–∞ –ø–æ—à—É–∫ —É—Ä–∞–∑–ª–∏–≤–æ—Å—Ç–µ–π",
        "competition_models": [
            "mistralai/codestral-latest",             # –ö–æ–¥-–∞—É–¥–∏—Ç
            "ai21-labs/ai21-jamba-1.5-large",        # –°–∫–ª–∞–¥–Ω–∞ –ª–æ–≥—ñ–∫–∞ –∞—Ç–∞–∫
            "meta-llama/meta-llama-3-70b-instruct"   # –ê–Ω–∞–ª—ñ–∑ –±–µ–∑–ø–µ–∫–∏
        ],
        "arbiter_model": "cohere/command-r-plus-08-2024",
        "fallback_chain": [
            "microsoft/phi-3-small-128k-instruct",
            "qwen/qwen2.5-32b-instruct",
            "google/gemma-2-27b-it"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "meta-llama/meta-llama-3-8b-instruct"],
        "max_concurrent": 2,
        "thermal_protection": {"enabled": True, "threshold": 0.90, "cooldown": 60},
        "load_balancing": "security_depth"
    },
    
    # üìã –ú–û–ù–Ü–¢–û–†–ò–ù–ì –¢–ê –û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–Ø
    "ComplianceMonitor": {
        "category": "compliance_monitoring",
        "specialization": "–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ —Ç–∞ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ñ –≤–∏–º–æ–≥–∏",
        "competition_models": [
            "cohere/command-r-plus-08-2024",         # –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω–∏–π —Ç–µ–∫—Å—Ç
            "microsoft/phi-3-small-128k-instruct",  # –î–æ–≤–≥—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏
            "qwen/qwen2.5-32b-instruct"              # –°–∫–ª–∞–¥–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "meta-llama/meta-llama-3-70b-instruct",
            "google/gemma-2-27b-it",
            "cohere/command-r-08-2024"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "qwen/qwen2.5-7b-instruct"],
        "max_concurrent": 4,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 35},
        "load_balancing": "compliance_accuracy"
    },
    
    "PerformanceOptimizer": {
        "category": "performance_optimization",
        "specialization": "–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Å–∏—Å—Ç–µ–º–∏",
        "competition_models": [
            "mistralai/codestral-latest",             # –ö–æ–¥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            "microsoft/phi-3-small-128k-instruct",   # –ê–Ω–∞–ª—ñ–∑ –º–µ—Ç—Ä–∏–∫
            "qwen/qwen2.5-32b-instruct"              # –ß–∏—Å–ª–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "meta-llama/meta-llama-3-8b-instruct",
            "cohere/command-r-plus-08-2024",
            "google/gemma-2-27b-it"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "qwen/qwen2.5-7b-instruct"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.80, "cooldown": 45},
        "load_balancing": "optimization_impact"
    },
    
    "SelfImprovement": {
        "category": "self_optimization",
        "specialization": "–°–∞–º–æ–≤–¥–æ—Å–∫–æ–Ω–∞–ª–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏",
        "competition_models": [
            "ai21-labs/ai21-jamba-1.5-large",        # –ú–µ—Ç–∞-–Ω–∞–≤—á–∞–Ω–Ω—è
            "mistralai/mixtral-8x7b-instruct-v0.1",  # –°–∫–ª–∞–¥–Ω–∞ –ª–æ–≥—ñ–∫–∞
            "meta-llama/meta-llama-3-70b-instruct"   # –°–∞–º–æ–∞–Ω–∞–ª—ñ–∑
        ],
        "arbiter_model": "cohere/command-r-plus-08-2024",
        "fallback_chain": [
            "qwen/qwen2.5-32b-instruct",
            "microsoft/phi-3-small-128k-instruct",
            "google/gemma-2-27b-it"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "meta-llama/meta-llama-3-8b-instruct"],
        "max_concurrent": 2,
        "thermal_protection": {"enabled": True, "threshold": 0.95, "cooldown": 120},
        "load_balancing": "learning_efficiency"
    },
    
    # üéØ –ê–†–ë–Ü–¢–†–ê–ñ –¢–ê –î–û–ü–û–ú–û–ì–ê
    "Arbiter": {
        "category": "decision_arbitration",
        "specialization": "–ê—Ä–±—ñ—Ç—Ä–∞–∂ —Ä—ñ—à–µ–Ω—å –º—ñ–∂ –∞–≥–µ–Ω—Ç–∞–º–∏",
        "competition_models": [
            "ai21-labs/ai21-jamba-1.5-large",        # –°–∫–ª–∞–¥–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è
            "meta-llama/meta-llama-3-70b-instruct",  # –õ–æ–≥—ñ—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
            "cohere/command-r-plus-08-2024"          # –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ—Å—Ç—å
        ],
        "arbiter_model": "mistralai/mixtral-8x7b-instruct-v0.1", # –ú–µ—Ç–∞-–∞—Ä–±—ñ—Ç—Ä
        "fallback_chain": [
            "qwen/qwen2.5-32b-instruct",
            "microsoft/phi-3-small-128k-instruct",
            "google/gemma-2-27b-it"
        ],
        "emergency_pool": ["mistralai/mistral-7b-instruct-v0.3", "meta-llama/meta-llama-3-8b-instruct"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.85, "cooldown": 50},
        "load_balancing": "decision_quality"
    },
    
    "NexusGuide": {
        "category": "user_assistance",
        "specialization": "–î–æ–ø–æ–º–æ–≥–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º —Ç–∞ –Ω–∞–≤—ñ–≥–∞—Ü—ñ—è",
        "competition_models": [
            "cohere/command-r-plus-08-2024",         # –ù–∞–π–∫—Ä–∞—â–∞ –¥–æ–ø–æ–º–æ–≥–∞
            "microsoft/phi-3-small-128k-instruct",  # –î–æ–≤–≥—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó
            "meta-llama/meta-llama-3-8b-instruct"   # –î—Ä—É–∂–Ω—ñ–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        ],
        "arbiter_model": "qwen/qwen2.5-32b-instruct",
        "fallback_chain": [
            "google/gemma-2-27b-it",
            "cohere/command-r-08-2024",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["microsoft/phi-3-mini-128k-instruct", "qwen/qwen2.5-7b-instruct"],
        "max_concurrent": 5,
        "thermal_protection": {"enabled": True, "threshold": 0.70, "cooldown": 20},
        "load_balancing": "user_satisfaction"
    },
    
    "SchemaMapper": {
        "category": "schema_analysis",
        "specialization": "–ê–Ω–∞–ª—ñ–∑ —Ç–∞ –º–∞–ø–ø—ñ–Ω–≥ —Å—Ö–µ–º –¥–∞–Ω–∏—Ö",
        "competition_models": [
            "microsoft/phi-3-small-128k-instruct",   # –î–æ–≤–≥—ñ —Å—Ö–µ–º–∏
            "qwen/qwen2.5-32b-instruct",             # –°–∫–ª–∞–¥–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
            "cohere/command-r-08-2024"               # –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
        ],
        "arbiter_model": "ai21-labs/ai21-jamba-1.5-large",
        "fallback_chain": [
            "meta-llama/meta-llama-3-8b-instruct",
            "google/gemma-2-27b-it",
            "mistralai/mistral-7b-instruct-v0.3"
        ],
        "emergency_pool": ["qwen/qwen2.5-7b-instruct", "microsoft/phi-3-mini-128k-instruct"],
        "max_concurrent": 3,
        "thermal_protection": {"enabled": True, "threshold": 0.75, "cooldown": 30},
        "load_balancing": "schema_complexity"
    }
}

def create_production_model_distribution():
    """üè≠ –°—Ç–≤–æ—Ä—é—î –ø—Ä–æ–¥–∞–∫—à–Ω —Ä–æ–∑–ø–æ–¥—ñ–ª –∑ –∫–æ–Ω–∫—É—Ä—Å–æ–º, –∞—Ä–±—ñ—Ç—Ä–∞–∂–µ–º —Ç–∞ –∑–∞—Ö–∏—Å—Ç–æ–º"""
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
    used_models = set()
    for agent_name, config in AGENT_SPECIFICATIONS.items():
        used_models.update(config.get("competition_models", []))
        used_models.update(config.get("fallback_chain", []))
        used_models.update(config.get("emergency_pool", []))
        if config.get("arbiter_model"):
            used_models.add(config["arbiter_model"])
    
    print(f"üîç –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(used_models)}/21")
    unused_models = set(ALL_MODELS) - used_models
    if unused_models:
        print(f"‚ö†Ô∏è  –ù–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –º–æ–¥–µ–ª—ñ: {unused_models}")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–¥–∞–∫—à–Ω –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
    config = {
        "metadata": {
            "version": "2.0",
            "created_at": "2025-09-28",
            "description": "–ü—Ä–æ–¥–∞–∫—à–Ω —Ä–æ–∑–ø–æ–¥—ñ–ª 21 –ø—Ä–∞—Ü—é—é—á–æ—ó –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ—ó –º–æ–¥–µ–ª—ñ",
            "total_models": len(ALL_MODELS),
            "total_agents": len(AGENT_SPECIFICATIONS),
            "strategy": "competition_arbitration_fallback_thermal"
        },
        
        "system_architecture": {
            "competition_enabled": True,
            "arbitration_enabled": True, 
            "thermal_protection": True,
            "auto_failover": True,
            "load_balancing": True,
            "cost_optimization": True,
            "reliability_first": True
        },
        
        "model_tiers": {
            "tier_1_premium": ALL_MODELS[:5],    # –ù–∞–π–ø–æ—Ç—É–∂–Ω—ñ—à—ñ
            "tier_2_balanced": ALL_MODELS[5:11], # –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ
            "tier_3_specialized": ALL_MODELS[11:16], # –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ
            "tier_4_fast": ALL_MODELS[16:21]     # –®–≤–∏–¥–∫—ñ
        },
        
        "agents": {},
        
        "competition_system": {
            "enabled": True,
            "strategy": "parallel_evaluation",
            "timeout_seconds": 30,
            "consensus_threshold": 0.7,
            "winner_selection": "best_score_fastest"
        },
        
        "arbitration_system": {
            "enabled": True,
            "arbiter_timeout": 15,
            "conflict_resolution": "weighted_vote",
            "escalation_levels": 3
        },
        
        "thermal_protection": {
            "global_enabled": True,
            "monitoring_interval": 5,
            "cooldown_strategies": [
                "reduce_concurrency",
                "switch_to_fallback", 
                "activate_emergency_pool",
                "temporary_shutdown"
            ]
        },
        
        "failover_system": {
            "enabled": True,
            "detection_time": 3,
            "recovery_attempts": 5,
            "cascade_prevention": True
        }
    }
    
    # –î–æ–¥–∞—î–º–æ –∞–≥–µ–Ω—Ç—ñ–≤ –∑ —ó—Ö–Ω—ñ–º–∏ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è–º–∏
    for agent_name, agent_config in AGENT_SPECIFICATIONS.items():
        config["agents"][agent_name] = {
            "category": agent_config["category"],
            "specialization": agent_config["specialization"],
            
            "model_strategy": {
                "competition_models": agent_config["competition_models"],
                "arbiter_model": agent_config["arbiter_model"],
                "fallback_chain": agent_config["fallback_chain"],
                "emergency_pool": agent_config["emergency_pool"]
            },
            
            "performance_settings": {
                "max_concurrent": agent_config["max_concurrent"],
                "load_balancing": agent_config["load_balancing"],
                "priority_level": "critical" if "critical" in agent_config["category"] else "normal"
            },
            
            "thermal_protection": agent_config["thermal_protection"],
            
            "reliability": {
                "retry_attempts": 3,
                "backoff_strategy": "exponential",
                "circuit_breaker": True,
                "health_checks": True
            }
        }
    
    return config

def save_production_configuration(config: Dict[str, Any]) -> str:
    """üíæ –ó–±–µ—Ä—ñ–≥–∞—î –ø—Ä–æ–¥–∞–∫—à–Ω –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é"""
    config_path = "/Users/dima/Documents/Predator11/agents/production_model_distribution.yaml"
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    return config_path

def update_production_registry(config: Dict[str, Any]) -> str:
    """üîÑ –û–Ω–æ–≤–ª—é—î –ø—Ä–æ–¥–∞–∫—à–Ω registry –∑ –Ω–æ–≤–æ—é –ª–æ–≥—ñ–∫–æ—é"""
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ LLM –ø—Ä–æ—Ñ—ñ–ª—ñ –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
    llm_profiles = {}
    
    # –ü—Ä–æ—Ñ—ñ–ª—ñ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è –º–æ–¥–µ–ª–µ–π
    tiers = config["model_tiers"]
    
    # TIER 1: –ö—Ä–∏—Ç–∏—á–Ω—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó
    llm_profiles["critical_tier1"] = {
        "provider": "sdk",
        "models": tiers["tier_1_premium"],
        "strategy": "competition_best_of_3",
        "max_tokens": 8192,
        "temperature": 0.1,
        "timeout": 30,
        "cost_per_1k_tokens": 0.0
    }
    
    # TIER 2: –ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó  
    llm_profiles["balanced_tier2"] = {
        "provider": "sdk", 
        "models": tiers["tier_2_balanced"],
        "strategy": "round_robin_with_fallback",
        "max_tokens": 4096,
        "temperature": 0.2,
        "timeout": 20,
        "cost_per_1k_tokens": 0.0
    }
    
    # TIER 3: –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó
    llm_profiles["specialized_tier3"] = {
        "provider": "sdk",
        "models": tiers["tier_3_specialized"],
        "strategy": "task_specific_selection",
        "max_tokens": 4096,
        "temperature": 0.15,
        "timeout": 25,
        "cost_per_1k_tokens": 0.0
    }
    
    # TIER 4: –®–≤–∏–¥–∫—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó
    llm_profiles["fast_tier4"] = {
        "provider": "sdk",
        "models": tiers["tier_4_fast"],
        "strategy": "fastest_response",
        "max_tokens": 2048,
        "temperature": 0.1,
        "timeout": 10,
        "cost_per_1k_tokens": 0.0
    }
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π registry
    new_registry = {
        "version": "2.0_production",
        "llm_profiles": llm_profiles,
        "agents": {}
    }
    
    # –ü—Ä–∏–≤'—è–∑—É—î–º–æ –∞–≥–µ–Ω—Ç—ñ–≤ –¥–æ –ø—Ä–æ—Ñ—ñ–ª—ñ–≤
    for agent_name, agent_config in config["agents"].items():
        category = agent_config["category"]
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–æ—Ñ—ñ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        if "critical" in category:
            profile = "critical_tier1"
        elif any(word in category for word in ["fast", "real_time", "speed"]):
            profile = "fast_tier4"  
        elif any(word in category for word in ["code", "security", "optimization"]):
            profile = "specialized_tier3"
        else:
            profile = "balanced_tier2"
            
        new_registry["agents"][agent_name] = {
            "llm_profile": profile,
            "competition_models": agent_config["model_strategy"]["competition_models"],
            "arbiter_model": agent_config["model_strategy"]["arbiter_model"], 
            "fallback_chain": agent_config["model_strategy"]["fallback_chain"],
            "emergency_pool": agent_config["model_strategy"]["emergency_pool"],
            "max_concurrent": agent_config["performance_settings"]["max_concurrent"],
            "load_balancing": agent_config["performance_settings"]["load_balancing"],
            "thermal_protection": agent_config["thermal_protection"]["enabled"],
            "priority": agent_config["performance_settings"]["priority_level"]
        }
    
    # –î–æ–¥–∞—î–º–æ —Å–∏—Å—Ç–µ–º–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    new_registry["system_config"] = {
        "competition_enabled": config["competition_system"]["enabled"],
        "arbitration_enabled": config["arbitration_system"]["enabled"],
        "thermal_protection": config["thermal_protection"]["global_enabled"],
        "failover_enabled": config["failover_system"]["enabled"]
    }
    
    # Kafka topics (–∑–∞–ª–∏—à–∞—î–º–æ —ñ—Å–Ω—É—é—á—ñ + –¥–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ)
    new_registry["kafka_topics"] = {
        "orchestrator": ["orchestrator.tasks", "orchestrator.results", "orchestrator.scaling", "orchestrator.competition"],
        "data_flow": ["data.ingest", "data.quality", "data.processed", "etl.status"],
        "agents_communication": ["agents.requests", "agents.responses", "agents.status", "agents.competition", "agents.arbitration"],
        "system_events": ["system.incidents", "system.notifications", "system.health", "system.alerts", "system.thermal"],
        "models": ["models.requests", "models.responses", "models.health", "models.failover", "models.competition", "models.arbitration"],
        "monitoring": ["monitoring.metrics", "monitoring.performance", "monitoring.thermal", "monitoring.costs"]
    }
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø—Ä–æ–¥–∞–∫—à–Ω registry
    registry_path = "/Users/dima/Documents/Predator11/agents/registry_production.yaml"
    with open(registry_path, 'w', encoding='utf-8') as f:
        yaml.dump(new_registry, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    return registry_path

if __name__ == "__main__":
    print("üè≠ –°–¢–í–û–†–ï–ù–ù–Ø –ü–†–û–î–ê–ö–®–ù –†–û–ó–ü–û–î–Ü–õ–£ 21 –ü–†–ê–¶–Æ–Æ–ß–û–á –ú–û–î–ï–õ–Ü")
    print("=" * 60)
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–¥–∞–∫—à–Ω —Ä–æ–∑–ø–æ–¥—ñ–ª
    config = create_production_model_distribution()
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
    config_path = save_production_configuration(config)
    print(f"‚úÖ –ü—Ä–æ–¥–∞–∫—à–Ω –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {config_path}")
    
    # –û–Ω–æ–≤–ª—é—î–º–æ registry
    registry_path = update_production_registry(config)
    print(f"‚úÖ –ü—Ä–æ–¥–∞–∫—à–Ω registry –æ–Ω–æ–≤–ª–µ–Ω–æ: {registry_path}")
    
    # –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –ü–†–û–î–ê–ö–®–ù –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"üî¢ –ü—Ä–∞—Ü—é—é—á–∏—Ö –º–æ–¥–µ–ª–µ–π: 21")
    print(f"ü§ñ –í—Å—å–æ–≥–æ –∞–≥–µ–Ω—Ç—ñ–≤: 26")
    print(f"üèÜ –ö–æ–Ω–∫—É—Ä—Å–Ω–∞ —Å–∏—Å—Ç–µ–º–∞: –ê–ö–¢–ò–í–ù–ê")
    print(f"‚öñÔ∏è  –°–∏—Å—Ç–µ–º–∞ –∞—Ä–±—ñ—Ç—Ä–∞–∂—É: –ê–ö–¢–ò–í–ù–ê") 
    print(f"üõ°Ô∏è  –¢–µ—Ä–º–∞–ª—å–Ω–∏–π –∑–∞—Ö–∏—Å—Ç: –ê–ö–¢–ò–í–ù–ò–ô")
    print(f"üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π failover: –ê–ö–¢–ò–í–ù–ò–ô")
    print(f"üí∞ –í–∞—Ä—Ç—ñ—Å—Ç—å: 100% –ë–ï–ó–ö–û–®–¢–û–í–ù–û")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä—ñ–≤–Ω—è—Ö
    tier_stats = {
        "–ö—Ä–∏—Ç–∏—á–Ω—ñ (Tier 1)": 5,
        "–ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ (Tier 2)": 6, 
        "–°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ (Tier 3)": 5,
        "–®–≤–∏–¥–∫—ñ (Tier 4)": 5
    }
    
    print(f"\nüè∑Ô∏è  –†–û–ó–ü–û–î–Ü–õ –ü–û –†–Ü–í–ù–Ø–•:")
    for tier, count in tier_stats.items():
        print(f"   {tier}: {count} –º–æ–¥–µ–ª–µ–π")
    
    print(f"\nüéØ –ü–†–û–î–ê–ö–®–ù –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê!")
    print(f"üí™ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π –ö–ü–î + –Ω—É–ª—å–æ–≤–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å")
    print(f"üö´ –ù–µ–∑–ª–∞–º–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –∑ –±–∞–≥–∞—Ç–æ—Ä—ñ–≤–Ω–µ–≤–∏–º –∑–∞—Ö–∏—Å—Ç–æ–º")
    print(f"‚ö° –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∏–π –≤—ñ–¥–±—ñ—Ä –Ω–∞–π–∫—Ä–∞—â–∏—Ö —Ä—ñ—à–µ–Ω—å")
