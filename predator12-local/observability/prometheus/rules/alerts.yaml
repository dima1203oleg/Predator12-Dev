---
groups:
  - name: app-alerts
    rules:
      - alert: HighLatency
        expr: 'histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job)) > 1'
        for: 1m
        labels:
          severity: critical
          deployment_name: '{{ $labels.job }}'
        annotations:
          summary: "High request latency on {{ $labels.job }}"
          description: "The 99th percentile of request latency is over 1 second for the job {{ $labels.job }}."

      - alert: HighErrorRate
        expr: 'sum(rate(http_requests_total{status=~"5.."}[5m])) by (job) / sum(rate(http_requests_total[5m])) by (job) > 0.05'
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High HTTP error rate on {{ $labels.job }}"
          description: "More than 5% of requests are failing with 5xx errors for the job {{ $labels.job }}."

      - alert: PostgresPrimaryDown
        expr: 'pg_up{role="primary"} == 0'
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL primary is down"
          description: "The primary PostgreSQL instance is not responding."

      - alert: OpenSearchClusterRed
        expr: 'opensearch_cluster_health_status{color="red"} == 1'
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "OpenSearch cluster is in red state"
          description: "The OpenSearch cluster is unhealthy and some data is unavailable."

      - alert: ETLJobFailed
        expr: 'sum(rate(etl_job_runs_total{status="failed"}[10m])) by (job_name) > 0'
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "ETL job {{ $labels.job_name }} failed"
          description: "The ETL job {{ $labels.job_name }} has failed to complete."

      - alert: ModelDriftDetected
        expr: 'model_drift_score > 0.7'
        for: 15m
        labels:
          severity: warning
          model_name: '{{ $labels.model_name }}'
        annotations:
          summary: "Data drift detected for model {{ $labels.model_name }}"
          description: "The input data for model {{ $labels.model_name }} has drifted significantly."

      - alert: SuspiciousPodActivity
        expr: 'sum(rate(falco_events{rule=~"Suspicious.*"}[5m])) by (pod_name) > 0'
        for: 1m
        labels:
          severity: high
          pod_name: '{{ $labels.pod_name }}'
        annotations:
          summary: "Suspicious activity detected in pod {{ $labels.pod_name }}"
          description: "Falco has detected suspicious activity in pod {{ $labels.pod_name }}. Please investigate."

  - name: etl-alerts
    rules:
      - alert: ETLJobFailed
        expr: etl_job_status == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "ETL job failed"
          description: "ETL job has failed for more than 5 minutes."
      # Detect ETL worker OOMKills within last 10 minutes
      - alert: ETLWorkerOOMKilled
        expr: sum by(pod) (increase(kube_pod_container_status_terminated_reason{reason="OOMKilled",container=~"etl-.*"}[10m])) > 0
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "ETL worker OOMKilled"
          description: "ETL worker pod experienced OOMKill in the last 10 minutes."

  - name: platform-alerts
    rules:
      # OpenSearch cluster health degraded
      - alert: OpenSearchClusterYellow
        expr: max(opensearch_cluster_health_status{color="yellow"}) == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "OpenSearch health YELLOW"
          description: "OpenSearch cluster reported YELLOW health for >5m."
      - alert: OpenSearchClusterRed
        expr: max(opensearch_cluster_health_status{color="red"}) == 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "OpenSearch health RED"
          description: "OpenSearch cluster reported RED health for >2m."
      - alert: OpenSearchClusterUnhealthy
        expr: opensearch_cluster_status{cluster="main"} != 0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "OpenSearch cluster is not green"
          description: "OpenSearch cluster status is yellow or red."

      # Postgres primary down
      - alert: PostgresPrimaryDown
        expr: pg_up == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Postgres primary down"
          description: "PostgreSQL exporter reports pg_up==0 for >2m."
      - alert: PostgresPrimaryDown
        expr: up{job="postgres-primary"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL primary is down"
          description: "Primary PostgreSQL instance is unavailable"

  - name: ml-alerts
    rules:
      # ML inference P95 latency high
      - alert: MLInferenceLatencyHigh
        expr: histogram_quantile(0.95, sum by (le) (rate(http_request_duration_seconds_bucket{job="ml-inference"}[5m]))) > 0.8
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "ML inference latency high (P95)"
          description: "P95 latency for ml-inference service exceeds 800ms for >5m."
      - alert: MLInferenceLatencyHigh
        expr: histogram_quantile(0.95, rate(ml_inference_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ML inference latency is high"
          description: "95th percentile latency > 1s"

  - name: security-alerts
    rules:
      # Falco suspicious activity
      - alert: FalcoSuspiciousActivity
        expr: increase(falco_events_total[5m]) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Falco detected suspicious activity"
          description: "Falco reported one or more security events in the last 5 minutes."
      - alert: SuspiciousExfilDetected
        expr: rate(falco_events{exfiltration="true"}[5m]) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Suspicious data exfiltration detected"
          description: "Falco detected potential data exfiltration"
